{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I participated in a competition organized by Lyft and Udacity in May 2018. Our task was to build a system to extract cars and road from videos recorded from [CARLA simulator](http://carla.org/).\n",
    "\n",
    "I used a semantic segmentation algorithm with deep learning system which achieved a car F-score of 0.8291 and road F-score of 0.9773 with FPS of 11.363. To build this algorithm, I used MobileUNet network with 22300 training data, augmented by horizontal flipping, color intensity adjustments, and image rotations.\n",
    "\n",
    "## 1. Model Architecture\n",
    "\n",
    "MobileUNet [\\[1\\]](#ref1) is a variation of MobileNet [\\[2\\]](#ref2) and UNet [\\[3\\]](#ref3). This specific architecture was chosen due to its higher inference speed compared to most semantic segmentation models.\n",
    "\n",
    "My implementation uses the following structure:\n",
    "\n",
    "| Layer               |     Description                                      |\n",
    "|:-------------------:|:----------------------------------------------------:|\n",
    "| Input               | 256x256x3 RGB image                                  |\n",
    "| *Downsampling path* |\n",
    "| **Block 1**         | Skip connection - add to **Block 8**                 |\n",
    "| ConvBlock           | Number of filters set to 64                          |\n",
    "| DSConvBlock         | Number of filters set to 64                          |\n",
    "| Max Pooling         | stride = [2, 2], pool size = [2, 2], padding = VALID |\n",
    "| **Block 2**         | Skip connection - add to **Block 7**                 |\n",
    "| ConvBlock           | Number of filters set to 128                         |\n",
    "| DSConvBlock         | Number of filters set to 128                         |\n",
    "| Max Pooling         | stride = [2, 2], pool size = [2, 2], padding = VALID |\n",
    "| **Block 3**         | Skip connection - add to **Block 6**                 |\n",
    "| ConvBlock           | Number of filters set to 256                         |\n",
    "| DSConvBlock         | Number of filters set to 256                         |\n",
    "| Max Pooling         | stride = [2, 2], pool size = [2, 2], padding = VALID |\n",
    "| **Block 4**         | Skip connection - add to **Block 5**                 |\n",
    "| ConvBlock           | Number of filters set to 512                         |\n",
    "| DSConvBlock         | Number of filters set to 512                         |\n",
    "| Max Pooling         | stride = [2, 2], pool size = [2, 2], padding = VALID |\n",
    "| *Upsampling path* |\n",
    "| **Block 5**         | Skip connection - add by **Block 4**                 |\n",
    "| ConvTransposeBlock  | Number of filters set to 512                         |\n",
    "| DSConvBlock         | Number of filters set to 512                         |\n",
    "| DSConvBlock         | Number of filters set to 512                         |\n",
    "| DSConvBlock         | Number of filters set to 512                         |\n",
    "| Add by **Block 4**  | Arithmetic add                                       |\n",
    "| **Block 6**         | Skip connection - add by **Block 3**                 |\n",
    "| ConvTransposeBlock  | Number of filters set to 512                         |\n",
    "| DSConvBlock         | Number of filters set to 512                         |\n",
    "| DSConvBlock         | Number of filters set to 512                         |\n",
    "| DSConvBlock         | Number of filters set to 256                         |\n",
    "| Add by **Block 4**  | Arithmetic add                                       |\n",
    "| **Block 7**         | Skip connection - add by **Block 2**                 |\n",
    "| ConvTransposeBlock  | Number of filters set to 256                         |\n",
    "| DSConvBlock         | Number of filters set to 128                         |\n",
    "| DSConvBlock         | Number of filters set to 128                         |\n",
    "| DSConvBlock         | Number of filters set to 128                         |\n",
    "| Add by **Block 4**  | Arithmetic add                                       |\n",
    "| **Block 8**         | Skip connection - add by **Block 1**                 |\n",
    "| ConvTransposeBlock  | Number of filters set to 128                         |\n",
    "| DSConvBlock         | Number of filters set to 128                         |\n",
    "| DSConvBlock         | Number of filters set to 64                          |\n",
    "| Add by **Block 4**  | Arithmetic add                                       |\n",
    "| ConvTransposeBlock  | Number of filters set to 64                          |\n",
    "| DSConvBlock         | Number of filters set to 64                          |\n",
    "| DSConvBlock         | Number of filters set to 64                          |\n",
    "| *Softmax* | |\n",
    "| Convolution         | filters = 3 (num. of classes), kernel = [1, 1], padding = SAME |\n",
    "\n",
    "Total number of classes is 3, for *Background*, *Road*, and *Car*.\n",
    "\n",
    "Each **ConvBlock** is an operation with the following architecture:\n",
    "\n",
    "| Layer                          |     Description                                   | \n",
    "|:------------------------------:|:-------------------------------------------------:|\n",
    "| Convolution                    | variable filters, kernel = [1, 1], padding = SAME |\n",
    "| Fused Batch Normalization      |  |\n",
    "| ReLu Activation                |  |\n",
    "\n",
    "All **Batch Normalizations** in the architecture are fused to improve their speed.\n",
    "\n",
    "**DSConvBlock** is short for Depthwise Separable Convolutional Block. Depthwise separable convolutions are used for mobile devices because of their efficient use of parameters. It has the following architecture:\n",
    "\n",
    "| Layer                                    |     Description                         | \n",
    "|:----------------------------------------:|:---------------------------------------:|\n",
    "| Separable Convolution       | kernel = [3, 3] depth multiplier = 1, padding = SAME |\n",
    "| Fused Batch Normalization   |  |\n",
    "| ReLu Activation             |  |\n",
    "| Convolution                 | variable filters, kernel = [1, 1], padding = SAME    |\n",
    "| Fused Batch Normalization   |  |\n",
    "| ReLu Activation             |  |\n",
    "\n",
    "**ConvTransposeBlock** is the upsampling operation to decode the activations.\n",
    "\n",
    "| Layer                                    |     Description                                      | \n",
    "|:----------------------------------------:|:----------------------------------------------------:|\n",
    "| Transpose Convolution       | variable filters, kernel = [3, 3] stride = [2, 2], padding = SAME |\n",
    "| Batch Normalization         |  |\n",
    "| ReLu Activation             |  |\n",
    "\n",
    "## 2. Training Data\n",
    "\n",
    "In this section, I will describe some preprocessing steps that were done in this project. All data were gathered by recording images from CARLA simulation on 800 x 600 pixels resolution. In addition to 1000 images provided by Lyft, I recorded 72 more runs, each contains 274 screenshots. Total images is then `1000 + (72 * 274) = 20728` images.\n",
    "\n",
    "### 2.1. Initial preprocessing\n",
    "\n",
    "These images are resized into 256 x 256 pixels to accommodate the model's input. Segmentation data are processed to only take the road and cars, convert everything else to background (including our car's hood), and reindex the segmentation (0 for background, 1 for road, and 2 for cars). Below are some examples of the training data:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
